# ğŸ•·ï¸ Scrapy í¬ë¡¤ëŸ¬ (Site Crawler for LLM)

ê°•ë ¥í•œ ì›¹ í¬ë¡¤ëŸ¬ - Scrapy + Playwright ê¸°ë°˜

## âœ¨ íŠ¹ì§•

- âœ… **Playwright ë Œë”ë§** - React/Vue/Angular ë“± SPA ì§€ì›
- âœ… **CSS ë°°ê²½ ì´ë¯¸ì§€** - computed styleì—ì„œ ì¶”ì¶œ
- âœ… **ë³¸ë¬¸ ì¶”ì¶œ** - readability-lxml ì‚¬ìš©
- âœ… **ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ** - ìë™ ì €ì¥ (ì„ íƒ ì‚¬í•­)
- âœ… **ê¹Šì´ ì œì–´** - ë§í¬ íƒìƒ‰ ê¹Šì´ ì„¤ì •
- âœ… **JSONL ì¶œë ¥** - êµ¬ì¡°í™”ëœ ë°ì´í„°

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
scrapy_setup/
â”œâ”€â”€ site_crawler/              # ë©”ì¸ í”„ë¡œì íŠ¸
â”‚   â”œâ”€â”€ spiders/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ site_spider.py    # í¬ë¡¤ë§ ë¡œì§
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ cssbg.py          # CSS ë°°ê²½ ì¶”ì¶œ
â”‚   â”‚   â”œâ”€â”€ text.py           # í…ìŠ¤íŠ¸ ì¶”ì¶œ
â”‚   â”‚   â””â”€â”€ urlnorm.py        # URL ì •ê·œí™”
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ items.py              # ë°ì´í„° êµ¬ì¡°
â”‚   â”œâ”€â”€ middlewares.py
â”‚   â”œâ”€â”€ pipelines.py          # ì €ì¥ ë¡œì§
â”‚   â””â”€â”€ settings.py           # ì„¤ì •
â”‚
â”œâ”€â”€ scrapy.cfg                # Scrapy ì„¤ì •
â”œâ”€â”€ requirements.txt          # íŒ¨í‚¤ì§€ ëª©ë¡
â”œâ”€â”€ setup.bat                 # ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ run.bat                   # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ run_nvidia.bat            # NVIDIA ë¬¸ì„œìš©
â””â”€â”€ README.md                 # ì´ íŒŒì¼
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1ë‹¨ê³„: ì„¤ì¹˜

```bash
# Windows
setup.bat ë”ë¸”í´ë¦­

# ìˆ˜ë™ ì„¤ì¹˜
pip install -r requirements.txt
playwright install chromium
```

**ì„¤ì¹˜ ì‹œê°„:** ì•½ 5-10ë¶„ (Chrome ë¸Œë¼ìš°ì € ë‹¤ìš´ë¡œë“œ í¬í•¨)

### 2ë‹¨ê³„: ì‹¤í–‰

#### ë°©ë²• 1: ê¸°ë³¸ ì‹¤í–‰ (GUI ì—†ìŒ)

```bash
run.bat
```

URLê³¼ ë„ë©”ì¸ì„ ì…ë ¥í•˜ë¼ê³  ë‚˜ì˜µë‹ˆë‹¤.

#### ë°©ë²• 2: ëª…ë ¹ì¤„ íŒŒë¼ë¯¸í„°

```bash
# Windows
run.bat "https://example.com" "example.com" 100

# ì§ì ‘ ì‹¤í–‰
scrapy crawl site -a seed="URL" -a allowed_domains="DOMAIN" -a max_pages=100
```

#### ë°©ë²• 3: NVIDIA ë¬¸ì„œ í¬ë¡¤ë§

```bash
run_nvidia.bat
```

## âš™ï¸ íŒŒë¼ë¯¸í„° ì„¤ëª…

| íŒŒë¼ë¯¸í„° | ì„¤ëª… | ê¸°ë³¸ê°’ | ì˜ˆì‹œ |
|----------|------|--------|------|
| `seed` | ì‹œì‘ URL | í•„ìˆ˜ | https://example.com |
| `allowed_domains` | í¬ë¡¤ë§ í—ˆìš© ë„ë©”ì¸ | í•„ìˆ˜ | example.com |
| `out_dir` | ì¶œë ¥ í´ë” | ./dump | ./output |
| `max_pages` | ìµœëŒ€ í˜ì´ì§€ ìˆ˜ | 500 | 100 |
| `max_depth` | ìµœëŒ€ ë§í¬ ê¹Šì´ | 4 | 3 |
| `render` | Playwright ì‚¬ìš© (0/1) | 1 | 0 |
| `include_css_bg` | CSS ë°°ê²½ ìˆ˜ì§‘ (0/1) | 1 | 0 |

## ğŸ“Š ì¶œë ¥ í˜•ì‹

### pages.jsonl

ê° ì¤„ì´ í•˜ë‚˜ì˜ í˜ì´ì§€ (JSONL í˜•ì‹):

```json
{
  "url": "https://example.com/page1",
  "final_url": "https://example.com/page1",
  "fetched_at": "2024-02-10T12:00:00+00:00",
  "status": 200,
  "rendered": true,
  "title": "Page Title",
  "text": "Main content text extracted by readability...",
  "images": [
    {
      "type": "img",
      "src": "https://example.com/image.jpg",
      "alt": "Image description",
      "local_path": "images/example.com/abc123/img.jpg"
    }
  ],
  "out_links": ["https://example.com/page2"],
  "depth": 0,
  "page_key": "abc123def456"
}
```

## ğŸ¯ ì‚¬ìš© ì˜ˆì‹œ

### ì˜ˆì‹œ 1: ë¸”ë¡œê·¸ í¬ë¡¤ë§

```bash
scrapy crawl site \
  -a seed="https://blog.example.com" \
  -a allowed_domains="blog.example.com" \
  -a max_pages=50
```

### ì˜ˆì‹œ 2: React ì•± í¬ë¡¤ë§ (ë Œë”ë§ í•„ìš”)

```bash
scrapy crawl site \
  -a seed="https://react-app.com" \
  -a allowed_domains="react-app.com" \
  -a render=1 \
  -a max_pages=100
```

### ì˜ˆì‹œ 3: ì •ì  ì‚¬ì´íŠ¸ (ë¹ ë¥¸ í¬ë¡¤ë§)

```bash
scrapy crawl site \
  -a seed="https://docs.example.com" \
  -a allowed_domains="docs.example.com" \
  -a render=0 \
  -a max_pages=200
```

### ì˜ˆì‹œ 4: NVIDIA DRIVE OS ë¬¸ì„œ

```bash
scrapy crawl site \
  -a seed="https://developer.nvidia.com/docs/drive/drive-os/6.0.10/public/drive-os-linux-sdk/api_reference/index.html" \
  -a allowed_domains="developer.nvidia.com" \
  -a out_dir="./nvidia_docs" \
  -a max_pages=500 \
  -a max_depth=4 \
  -a render=0
```

## âš¡ ì„±ëŠ¥ ìµœì í™”

### ë¹ ë¥¸ í¬ë¡¤ë§ (ì •ì  ì‚¬ì´íŠ¸)

```bash
scrapy crawl site \
  -a render=0 \              # Playwright ë¹„í™œì„±í™”
  -a include_css_bg=0 \      # CSS ë°°ê²½ ë¹„í™œì„±í™”
  -a max_pages=1000
```

### ëŠë¦¬ì§€ë§Œ ì™„ì „í•œ í¬ë¡¤ë§ (SPA)

```bash
scrapy crawl site \
  -a render=1 \              # Playwright í™œì„±í™”
  -a include_css_bg=1 \      # CSS ë°°ê²½ í™œì„±í™”
  -a max_pages=100
```

## ğŸ”§ ì„¤ì • ìˆ˜ì •

`site_crawler/settings.py` íŒŒì¼ì—ì„œ:

```python
# ë™ì‹œ ìš”ì²­ ìˆ˜
CONCURRENT_REQUESTS = 16

# ë‹¤ìš´ë¡œë“œ ì§€ì—°
DOWNLOAD_DELAY = 0.25

# Playwright í˜ì´ì§€ ìˆ˜
PLAYWRIGHT_MAX_PAGES_PER_CONTEXT = 4
```

## â“ ë¬¸ì œ í•´ê²°

### "scrapy: command not found"

```bash
pip install scrapy
```

### "playwright: command not found"

```bash
pip install playwright
playwright install chromium
```

### í¬ë¡¤ë§ì´ ë„ˆë¬´ ëŠë¦¼

- `render=0` ì„¤ì • (Playwright ë¹„í™œì„±í™”)
- `include_css_bg=0` ì„¤ì •
- `max_depth=2` (ê¹Šì´ ì¤„ì´ê¸°)
- `CONCURRENT_REQUESTS=32` (ë™ì‹œ ìš”ì²­ ì¦ê°€)

### ë©”ëª¨ë¦¬ ë¶€ì¡±

- `max_pages` ì¤„ì´ê¸°
- `PLAYWRIGHT_MAX_PAGES_PER_CONTEXT=2` (ë¸Œë¼ìš°ì € í˜ì´ì§€ ìˆ˜ ì¤„ì´ê¸°)

### íŠ¹ì • ì‚¬ì´íŠ¸ê°€ ì°¨ë‹¨í•¨

- `DOWNLOAD_DELAY=2` (ì§€ì—° ì‹œê°„ ì¦ê°€)
- User-Agent ë³€ê²½

## ğŸ“ ë°ì´í„° ì²˜ë¦¬

### JSONL ì½ê¸° (Python)

```python
import json

with open('output/pages.jsonl', 'r', encoding='utf-8') as f:
    for line in f:
        page = json.loads(line)
        print(f"Title: {page['title']}")
        print(f"Text: {page['text'][:100]}...")
        print()
```

### JSONL â†’ CSV ë³€í™˜

```python
import json
import csv

pages = []
with open('output/pages.jsonl', 'r', encoding='utf-8') as f:
    for line in f:
        pages.append(json.loads(line))

with open('output.csv', 'w', newline='', encoding='utf-8') as f:
    writer = csv.DictWriter(f, fieldnames=['url', 'title', 'text'])
    writer.writeheader()
    for page in pages:
        writer.writerow({
            'url': page['url'],
            'title': page['title'],
            'text': page['text']
        })
```

## ğŸ†š vs ë‚´ Doxygen í¬ë¡¤ëŸ¬

| í•­ëª© | Scrapy í¬ë¡¤ëŸ¬ | Doxygen í¬ë¡¤ëŸ¬ |
|------|--------------|----------------|
| **ì„¤ì¹˜** | ë³µì¡ (4ê°œ íŒ¨í‚¤ì§€) | ê°„ë‹¨ (2ê°œ íŒ¨í‚¤ì§€) |
| **ì‹¤í–‰** | ëª…ë ¹ì¤„ | GUI âœ… |
| **ì†ë„** | ì¤‘ê°„ | ë¹ ë¦„ âœ… |
| **ë Œë”ë§** | Playwright âœ… | ì—†ìŒ |
| **ìš©ë„** | ëª¨ë“  ì›¹ì‚¬ì´íŠ¸ âœ… | Doxygenë§Œ |
| **ì¶œë ¥** | JSONL | TXT âœ… |
| **ì´ë¯¸ì§€** | ë‹¤ìš´ë¡œë“œ âœ… | ì—†ìŒ |

## ğŸ’¡ ì–¸ì œ ì‚¬ìš©?

### Scrapy í¬ë¡¤ëŸ¬ ì‚¬ìš©:
- âœ… React/Vue/Angular ë“± SPA ì‚¬ì´íŠ¸
- âœ… ë‹¤ì–‘í•œ ì›¹ì‚¬ì´íŠ¸ í¬ë¡¤ë§
- âœ… ì´ë¯¸ì§€ ìˆ˜ì§‘ í•„ìš”
- âœ… ëŒ€ëŸ‰ í¬ë¡¤ë§ (1000+ í˜ì´ì§€)

### Doxygen í¬ë¡¤ëŸ¬ ì‚¬ìš©:
- âœ… Doxygen API ë¬¸ì„œ
- âœ… ì •ì  HTML ë¬¸ì„œ
- âœ… GUI ì„ í˜¸
- âœ… TXT íŒŒì¼ ì¶œë ¥ í•„ìš”

## ğŸ“„ ë¼ì´ì„¼ìŠ¤

MIT License

## ğŸ¤ í¬ë ˆë”§

Original: https://github.com/yourusername/site-crawler-for-llm
