# 완성! Doxygen 문서 크롤러

## 최종 업데이트: 개별 파일 저장 + PDF 지원!

### 당신이 원하는 기능
- 크롤링: 프로그램이 자동으로
- 각 페이지를 **개별 TXT 파일**로 저장
- 파일명: `001_제목_시간.txt` 형식
- **PDF도 TXT로 자동 변환!**

---

## 결과물 예시

### 400개 페이지 크롤링 시:

```
doxygen_crawl/
├── crawl_원문/                           ← 400개의 개별 TXT 파일!
│   ├── 001_NVIDIA_DRIVE_OS_API_20240205_143022.txt
│   ├── 002_Modules_List_20240205_143022.txt
│   ├── 003_[PDF]_User_Manual_20240205_143022.txt      ← PDF를 TXT로 변환!
│   ├── 004_NvMedia_ICP_Class_20240205_143022.txt
│   ├── 005_Thermal_Monitor_20240205_143022.txt
│   ├── 006_Power_Management_20240205_143022.txt
│   │   ... (394개 더)
│   └── 400_Final_Page_20240205_143022.txt
│
├── crawl_요약본/
│   └── 크롤링_요약.txt                    ← 전체 파일 목록
│
└── crawlJson/
    └── crawl_results.json                ← JSON 데이터
```

---

## 사용 방법

### 1️가장 쉬운 방법 (GUI)

```
run_doxygen_gui.bat 더블클릭!
```

### 명령줄

```batch
run_doxygen.bat "https://developer.nvidia.com/docs/drive/drive-os/6.0.10/public/drive-os-linux-sdk/api_reference/index.html"
```

---

## 파일명 형식

```
{순번}_{제목}_{시간}.txt
{순번}_[PDF]_{제목}_{시간}.txt  ← PDF 파일인 경우

순번: 001, 002, 003... (3자리)
제목: 페이지 제목 (특수문자 제거)
시간: 20240205_143022 (년월일_시분초)

예시:
001_NVIDIA_DRIVE_OS_Linux_SDK_API_Reference_20240205_143022.txt
003_[PDF]_Installation_Guide_20240205_143022.txt  ← PDF 변환!
150_Thermal_Monitor_API_20240205_143022.txt
```

---

## 크롤링 vs 요약

### 크롤링
- **프로그램이 자동으로**
- 웹페이지 방문
- 내용 수집
- 개별 TXT 파일로 저장

### 요약 (현재)
- **사람이 직접 확인**
- `크롤링_요약.txt`에 파일 목록
- 각 페이지의 제목과 URL
- 첫 200자 미리보기

### 요약 (미래 - AI 추가 시)
- **Claude AI가 자동으로**
- 각 페이지 내용 분석
- 핵심 요약 생성
- 별도 요약 파일 저장
---

## 왜 Doxygen 크롤러인가?

### 일반 크롤러의 문제
```
발견된 링크: 1개
총 페이지: 1개
```

### Doxygen 크롤러 
```
발견된 HTML 페이지: 150개
총 페이지: 150개
개별 TXT 파일: 150개
```

**이유:**
- NVIDIA 문서는 Doxygen으로 생성됨
- `modules.html`, `classes.html` 등 자동 탐색
- 모든 HTML 파일 수집

---

## 제공된 파일

### Doxygen 크롤러 (NVIDIA용)
1. **run_doxygen_gui.bat** - GUI 실행 (더블클릭!)
2. **run_doxygen.bat** - 명령줄 실행
3. **doxygen_crawler_gui.py** - GUI 프로그램
4. **doxygen_crawler.py** - 명령줄 프로그램
5. **DOXYGEN_가이드.md** - 상세 가이드

### 일반 크롤러 (다른 사이트용)
- `doc_crawler_gui_v2.py`
- `doc_crawler_v2.py`

---

## Q&A

**Q: 크롤링은 누가 하나요?**
A: 프로그램이 자동으로 합니다!

**Q: 요약은 누가 하나요?**
A: 현재는 간단 요약(제목+200자)만 자동입니다. AI 자동 요약이 필요하면 추가 가능합니다!

**Q: 400개 페이지면 400개 파일이 나오나요?**
A: 네! 각 페이지마다 개별 TXT 파일이 생성됩니다.

**Q: 파일명은 어떻게 되나요?**
A: `001_페이지제목_20240205_143022.txt` 형식입니다.

**Q: 하나의 큰 파일로 저장할 수는 없나요?**
A: 개별 파일이 관리하기 더 좋습니다만, 필요하시면 수정 가능합니다.

**Q: AI 요약이 필요한데요?**
A: Claude API를 사용한 자동 요약 기능을 추가할 수 있습니다. 말씀해주세요!

---

## 지금 바로 시작!

```
1. run_doxygen_gui.bat 더블클릭
2. NVIDIA URL 입력
3. "크롤링 시작" 클릭
4. crawl_원문 폴더에서 개별 파일 확인!
```

**400개 페이지 → 400개 TXT 파일!**

---

## 추가 기능 요청

다음 기능이 필요하시면 말씀해주세요:
- [ ] AI 자동 요약 (Claude API 사용)
- [ ] Markdown 파일로 저장
- [ ] PDF로 변환
- [ ] 특정 키워드만 필터링
- [ ] 기타...
